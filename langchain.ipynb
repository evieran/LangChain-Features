{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d9a34e8-38ba-492e-bca1-4baac1cab90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('keys.env')\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c632c4d-3836-4fa8-8a7d-d72277c81207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b077e6f4-f0cb-434e-afb1-1dd1b050bac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to learn Python. What is the first thing I should learn? Answer shortly and accurately.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = ['subject'],\n",
    "    template = \"I want to learn {subject}. What is the first thing I should learn? Answer shortly and accurately.\"\n",
    ")\n",
    "\n",
    "prompt_template_name.format(subject=\"Python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ffe0ead-9f53-47d6-8d68-0e1383664181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe first thing to learn when starting to learn SQL is the basic syntax and keywords, such as SELECT, FROM, WHERE, INSERT, UPDATE, and DELETE.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "chain.run(\"SQL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39e13a9f-ac04-4767-b2a0-3ad6f3bac29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = ['subject'],\n",
    "    template = \"I want to start a new business for {subject}. Suggest a funny name for the company.\"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['business_name'],\n",
    "    template = \"Suggest some items for {business_name}. Return it as a comma separated list\"\n",
    ")\n",
    "\n",
    "items_chain = LLMChain(llm=llm, prompt=prompt_template_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "925f45a2-b351-4766-9953-7d8c8a587e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Coffee beans, Tea leaves, Energy drinks, Espresso machines, French presses, Coffee grinders, Coffee mugs, Milk frothers, Tea kettles, Coffee filters, Sugar cubes, Creamers, Espresso cups, Coffee thermoses, Tea infusers.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains = [name_chain, items_chain])\n",
    "response = chain.run(\"Coffee\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "020ce06d-e75a-4f1e-993d-2d1b6061d294",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = ['subject'],\n",
    "    template = \"I want to start a new business for {subject}. Suggest a funny name for the company.\"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name, output_key='business_name')\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['business_name'],\n",
    "    template = \"Suggest some items for {business_name}. Return it as a comma separated list\"\n",
    ")\n",
    "\n",
    "items_chain = LLMChain(llm=llm, prompt=prompt_template_items, output_key='items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3570b39-b4d2-4930-bdae-dbc01687e662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': 'Coffee',\n",
       " 'business_name': '\\n\\nJava Jive!',\n",
       " 'items': '\\n\\nCoffee Mugs, Coffee Beans, Espresso Machine, Coffee Grinder, French Press, Coffee Scoop, Sugar Cubes, Creamer, K-Cups, Honey, Cocoa Powder, Tea Infuser, Tea Kettle, Tea Bags, Coffee Filter, Milk Frother'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains = [name_chain, items_chain],\n",
    "    input_variables = ['subject'],\n",
    "    output_variables = ['business_name', 'items']\n",
    ")\n",
    "\n",
    "chain({'subject': 'Coffee'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "faed01f9-ac05-4fed-adae-acb699808311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from wikipedia) (4.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from wikipedia) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.7.22)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from beautifulsoup4->wikipedia) (2.4.1)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=8e23ee8be863ec0528aab8c1d137e14744669686870857b9b01508d24cad2ed9\n",
      "  Stored in directory: /Users/evierangelova/Library/Caches/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
      "Successfully built wikipedia\n",
      "\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "36d0fbd5-592e-478a-b75a-ea88055cb3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Sam Altman is a person so I should search for him on Wikipedia.\n",
      "Action: Wikipedia\n",
      "Action Input: Sam Altman\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Sam Altman\n",
      "Summary: Samuel Harris Altman ( AWLT-mən; born 1985) is an American entrepreneur, investor, and programmer. He was the co-founder of Loopt and is the current CEO of OpenAI. He was the president of Y Combinator and was briefly the CEO of Reddit.\n",
      "\n",
      "\n",
      "\n",
      "Page: OpenAI\n",
      "Summary: OpenAI is an American artificial intelligence (AI) research laboratory consisting of the non-profit OpenAI, Inc. and its for-profit subsidiary corporation OpenAI, L.P.. OpenAI conducts research on artificial intelligence with the declared intention of developing \"safe and beneficial\" artificial general intelligence, which it defines as \"highly autonomous systems that outperform humans at most economically valuable work\".OpenAI was founded in 2015 by Ilya Sutskever, Greg Brockman, Trevor Blackwell, Vicki Cheung, Andrej Karpathy, Durk Kingma, Jessica Livingston, John Schulman, Pamela Vagata, and Wojciech Zaremba, with Sam Altman and Elon Musk serving as the initial board members. Microsoft provided OpenAI LP with a $1 billion investment in 2019 and a $10 billion investment in 2023.OpenAI has been criticized for its data curation practices of exposing developing world contractors to graphic textual content without psychosocial support.\n",
      "\n",
      "Page: Worldcoin\n",
      "Summary: Worldcoin is an iris biometric cryptocurrency project developed by San Francisco and Berlin-based Tools for Humanity. Founded in 2019 by OpenAI chief executive Sam Altman, Max Novendstern, and Alex Blania, it is backed by VC Andreessen Horowitz.\n",
      "\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I have all the necessary information to answer the question.\n",
      "Final Answer: Sam Altman was born in 1985 and will be 38 years old in 2023.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sam Altman was born in 1985 and will be 38 years old in 2023.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent.run(\"When was Sam Altman born? What is his age in 2023?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c342b525-d352-4483-80d3-7367b91b1796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "convo = ConversationChain(llm=OpenAI(temperature=0.7))\n",
    "print(convo.prompt.template)\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b347b760-4249-480f-a16a-d99d8e3d936b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The last World Cup was won by France in 2018. They defeated Croatia 4–2 in the final.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"Who won the last world cup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be7dc6bf-93d0-4795-9050-fa6551fa5d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 5+7 is equal to 12.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"What is 5+7?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b8d3f9b0-5fd0-42eb-b3c4-7be2fbacf672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The captain of the 2018 French World Cup winning team was Hugo Lloris.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"Who was the capitan of the winning team?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "69b0e8c1-35f3-406e-b9fe-d94a9aa3fc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Who won the world cup in december 2022?\n",
      "AI:  I'm sorry, I don't know the answer to that question.\n",
      "Human: Who won the last world cup\n",
      "AI:  The last World Cup was won by France in 2018. They defeated Croatia 4–2 in the final.\n",
      "Human: What is 5+7?\n",
      "AI:  5+7 is equal to 12.\n",
      "Human: Who was the capitan of the winning team?\n",
      "AI:  The captain of the 2018 French World Cup winning team was Hugo Lloris.\n"
     ]
    }
   ],
   "source": [
    "print(convo.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d9806a4c-d6e5-4315-8d5d-75d5ffe18879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' France won the 2018 FIFA World Cup in Russia. They defeated Croatia 4–2 in the final.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory (k=1)\n",
    "\n",
    "convo = ConversationChain(\n",
    "    llm = OpenAI(temperature=0.7),\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "convo.run(\"Who won the last world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7479c0b4-b9ac-4fd7-a687-b8d07f149e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 12.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"What is 5+7?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6f7f744-83d1-4a79-92a4-b88877dc0bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I'm sorry, I don't know.\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"Who was the capitan of the winning team?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b9a475-ec5f-4250-bd74-3eb10e79be8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
